{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIDXUkMElkDd"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hj40LjUilpix"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRg-5igLuoiI"
      },
      "source": [
        "#numpy for arrays, matplotlib for visualization, pandas to read and transform data from csv or xls files\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zApSnwUkl9eD"
      },
      "source": [
        "## Importing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjAi2fGLvGvK"
      },
      "source": [
        "data_set = pd.read_csv('Covid_Data.csv')\n",
        "X = data_set.iloc[:, :-1].values\n",
        "y = data_set.iloc[:, -1].values\n",
        "#print(y)\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaG0s7WjmgPU"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "## Handling Missing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrao100Bx0GF"
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(missing_values = np.nan, strategy = 'mean')\n",
        "\n",
        "imputer.fit(X[:, 0:5:4])\n",
        "X[: , 0:5:4] = imputer.transform(X[:, 0:5:4])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZ31gjqzz9FC",
        "outputId": "58215c69-71fd-49ba-fccd-f4c4bce0ab36"
      },
      "source": [
        "print(X)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[10.0 'Normal' 'no' 'no' 97.0]\n",
            " [12.0 'Normal' 'no' 'no' 97.0]\n",
            " [15.0 'Normal' 'no' 'no' 94.0]\n",
            " [10.0 'Normal' 'no' 'no' 97.0]\n",
            " [13.0 'Moderate' 'no' 'no' 94.0]\n",
            " [12.0 'Moderate' 'no' 'no' 97.0]\n",
            " [13.0 'Moderate' 'no' 'no' 93.0]\n",
            " [15.0 'Moderate' 'no' 'no' 92.0]\n",
            " [18.0 'Moderate' 'no' 'no' 66.0]\n",
            " [19.0 'Normal' 'no' 'no' 92.0]\n",
            " [20.0 'Normal' 'no' 'no' 93.0]\n",
            " [17.0 'Normal' 'no' 'no' 93.0]\n",
            " [16.0 'Normal' 'no' 'no' 92.0]\n",
            " [18.0 'Normal' 'no' 'no' 93.0]\n",
            " [20.0 'Normal' 'no' 'no' 92.0]\n",
            " [25.0 'Moderate' 'no' 'no' 93.0]\n",
            " [24.0 'Moderate' 'no' 'no' 92.0]\n",
            " [26.0 'High' 'no' 'no' 94.0]\n",
            " [28.0 'Normal' 'no' 'no' 99.0]\n",
            " [29.0 'Normal' 'no' 'no' 93.0]\n",
            " [30.0 'Moderate' 'no' 'no' 62.0]\n",
            " [19.0 'Normal' 'no' 'no' 89.0]\n",
            " [25.0 'Normal' 'no' 'yes' 86.0]\n",
            " [26.0 'Normal' 'no' 'no' 82.07246376811594]\n",
            " [28.0 'Normal' 'no' 'no' 89.0]\n",
            " [30.0 'Moderate' 'yes' 'no' 86.0]\n",
            " [35.0 'Moderate' 'no' 'no' 89.0]\n",
            " [32.0 'Moderate' 'no' 'yes' 84.0]\n",
            " [45.130434782608695 'Moderate' 'yes' 'no' 90.0]\n",
            " [32.0 'Moderate' 'no' 'no' 89.0]\n",
            " [35.0 'Moderate' 'no' 'yes' 92.0]\n",
            " [38.0 'High' 'no' 'no' 75.0]\n",
            " [40.0 'Moderate' 'no' 'yes' 90.0]\n",
            " [46.0 'High' 'yes' 'no' 91.0]\n",
            " [48.0 'Moderate' 'no' 'yes' 93.0]\n",
            " [42.0 'High' 'no' 'no' 92.0]\n",
            " [40.0 'High' 'no' 'no' 92.0]\n",
            " [49.0 'Moderate' 'no' 'no' 80.0]\n",
            " [50.0 'High' 'yes' 'yes' 77.0]\n",
            " [36.0 'High' 'yes' 'no' 90.0]\n",
            " [52.0 'High' 'yes' 'yes' 80.0]\n",
            " [56.0 'High' 'yes' 'yes' 77.0]\n",
            " [58.0 'High' 'no' 'no' 70.0]\n",
            " [59.0 'High' 'no' 'yes' 69.0]\n",
            " [60.0 'High' 'yes' 'yes' 68.0]\n",
            " [53.0 'High' 'yes' 'no' 55.0]\n",
            " [54.0 'High' 'yes' 'yes' 70.0]\n",
            " [62.0 'High' 'yes' 'yes' 68.0]\n",
            " [63.0 'High' 'yes' 'yes' 66.0]\n",
            " [68.0 'High' 'yes' 'no' 67.0]\n",
            " [69.0 'High' 'no' 'yes' 53.0]\n",
            " [64.0 'High' 'yes' 'yes' 73.0]\n",
            " [61.0 'High' 'yes' 'yes' 76.0]\n",
            " [70.0 'Normal' 'no' 'yes' 88.0]\n",
            " [59.0 'High' 'yes' 'no' 68.0]\n",
            " [62.0 'High' 'yes' 'yes' 69.0]\n",
            " [78.0 'High' 'yes' 'yes' 71.0]\n",
            " [74.0 'High' 'yes' 'yes' 75.0]\n",
            " [75.0 'High' 'no' 'yes' 72.0]\n",
            " [56.0 'High' 'yes' 'no' 76.0]\n",
            " [80.0 'High' 'no' 'yes' 92.0]\n",
            " [82.0 'High' 'yes' 'yes' 73.0]\n",
            " [86.0 'High' 'yes' 'yes' 71.0]\n",
            " [90.0 'High' 'yes' 'yes' 67.0]\n",
            " [84.0 'High' 'yes' 'yes' 75.0]\n",
            " [86.0 'High' 'no' 'yes' 76.0]\n",
            " [61.0 'Moderate' 'no' 'yes' 90.0]\n",
            " [94.0 'High' 'yes' 'yes' 64.0]\n",
            " [81.0 'High' 'yes' 'yes' 75.0]\n",
            " [76.0 'High' 'yes' 'yes' 80.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0syRbsSmkoe"
      },
      "source": [
        "## Encoding Categorical Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alHfpomamsVr"
      },
      "source": [
        "### Encoding independent variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbMLV_pC-RvL"
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For encoding of chronic_disease cloumn\n",
        "LeX1=LabelEncoder()\n",
        "X[:,2]=LeX1.fit_transform(X[:,2])"
      ],
      "metadata": {
        "id": "beXHRO-PGZMo"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X[1,:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuPIdkEjHDu6",
        "outputId": "4bc8ed32-42af-4ea2-c527-7ef2f362f5a7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12.0 'Normal' 0 'no' 97.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#For encoding of breathing_issue data\n",
        "LeX2=LabelEncoder()\n",
        "X[:,3]=LeX2.fit_transform(X[:,3])"
      ],
      "metadata": {
        "id": "izun6CkyGviI"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X[22,:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clC12F1WHLiF",
        "outputId": "0e173b74-3d72-421c-fa28-2f8cdad77139"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[25.0 'Normal' 0 1 86.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_t-rf29-dSP"
      },
      "source": [
        "ct = ColumnTransformer(transformers=[('encoder',OneHotEncoder(), [1])], remainder= 'passthrough')\n",
        "X = np.array(ct.fit_transform(X))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buoXf8Z0_FhM",
        "outputId": "b71dd88d-d232-4c80-c5e2-f4a747634ee7"
      },
      "source": [
        "print(X)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 0.0 1.0 10.0 0 0 97.0]\n",
            " [0.0 0.0 1.0 12.0 0 0 97.0]\n",
            " [0.0 0.0 1.0 15.0 0 0 94.0]\n",
            " [0.0 0.0 1.0 10.0 0 0 97.0]\n",
            " [0.0 1.0 0.0 13.0 0 0 94.0]\n",
            " [0.0 1.0 0.0 12.0 0 0 97.0]\n",
            " [0.0 1.0 0.0 13.0 0 0 93.0]\n",
            " [0.0 1.0 0.0 15.0 0 0 92.0]\n",
            " [0.0 1.0 0.0 18.0 0 0 66.0]\n",
            " [0.0 0.0 1.0 19.0 0 0 92.0]\n",
            " [0.0 0.0 1.0 20.0 0 0 93.0]\n",
            " [0.0 0.0 1.0 17.0 0 0 93.0]\n",
            " [0.0 0.0 1.0 16.0 0 0 92.0]\n",
            " [0.0 0.0 1.0 18.0 0 0 93.0]\n",
            " [0.0 0.0 1.0 20.0 0 0 92.0]\n",
            " [0.0 1.0 0.0 25.0 0 0 93.0]\n",
            " [0.0 1.0 0.0 24.0 0 0 92.0]\n",
            " [1.0 0.0 0.0 26.0 0 0 94.0]\n",
            " [0.0 0.0 1.0 28.0 0 0 99.0]\n",
            " [0.0 0.0 1.0 29.0 0 0 93.0]\n",
            " [0.0 1.0 0.0 30.0 0 0 62.0]\n",
            " [0.0 0.0 1.0 19.0 0 0 89.0]\n",
            " [0.0 0.0 1.0 25.0 0 1 86.0]\n",
            " [0.0 0.0 1.0 26.0 0 0 82.07246376811594]\n",
            " [0.0 0.0 1.0 28.0 0 0 89.0]\n",
            " [0.0 1.0 0.0 30.0 1 0 86.0]\n",
            " [0.0 1.0 0.0 35.0 0 0 89.0]\n",
            " [0.0 1.0 0.0 32.0 0 1 84.0]\n",
            " [0.0 1.0 0.0 45.130434782608695 1 0 90.0]\n",
            " [0.0 1.0 0.0 32.0 0 0 89.0]\n",
            " [0.0 1.0 0.0 35.0 0 1 92.0]\n",
            " [1.0 0.0 0.0 38.0 0 0 75.0]\n",
            " [0.0 1.0 0.0 40.0 0 1 90.0]\n",
            " [1.0 0.0 0.0 46.0 1 0 91.0]\n",
            " [0.0 1.0 0.0 48.0 0 1 93.0]\n",
            " [1.0 0.0 0.0 42.0 0 0 92.0]\n",
            " [1.0 0.0 0.0 40.0 0 0 92.0]\n",
            " [0.0 1.0 0.0 49.0 0 0 80.0]\n",
            " [1.0 0.0 0.0 50.0 1 1 77.0]\n",
            " [1.0 0.0 0.0 36.0 1 0 90.0]\n",
            " [1.0 0.0 0.0 52.0 1 1 80.0]\n",
            " [1.0 0.0 0.0 56.0 1 1 77.0]\n",
            " [1.0 0.0 0.0 58.0 0 0 70.0]\n",
            " [1.0 0.0 0.0 59.0 0 1 69.0]\n",
            " [1.0 0.0 0.0 60.0 1 1 68.0]\n",
            " [1.0 0.0 0.0 53.0 1 0 55.0]\n",
            " [1.0 0.0 0.0 54.0 1 1 70.0]\n",
            " [1.0 0.0 0.0 62.0 1 1 68.0]\n",
            " [1.0 0.0 0.0 63.0 1 1 66.0]\n",
            " [1.0 0.0 0.0 68.0 1 0 67.0]\n",
            " [1.0 0.0 0.0 69.0 0 1 53.0]\n",
            " [1.0 0.0 0.0 64.0 1 1 73.0]\n",
            " [1.0 0.0 0.0 61.0 1 1 76.0]\n",
            " [0.0 0.0 1.0 70.0 0 1 88.0]\n",
            " [1.0 0.0 0.0 59.0 1 0 68.0]\n",
            " [1.0 0.0 0.0 62.0 1 1 69.0]\n",
            " [1.0 0.0 0.0 78.0 1 1 71.0]\n",
            " [1.0 0.0 0.0 74.0 1 1 75.0]\n",
            " [1.0 0.0 0.0 75.0 0 1 72.0]\n",
            " [1.0 0.0 0.0 56.0 1 0 76.0]\n",
            " [1.0 0.0 0.0 80.0 0 1 92.0]\n",
            " [1.0 0.0 0.0 82.0 1 1 73.0]\n",
            " [1.0 0.0 0.0 86.0 1 1 71.0]\n",
            " [1.0 0.0 0.0 90.0 1 1 67.0]\n",
            " [1.0 0.0 0.0 84.0 1 1 75.0]\n",
            " [1.0 0.0 0.0 86.0 0 1 76.0]\n",
            " [0.0 1.0 0.0 61.0 0 1 90.0]\n",
            " [1.0 0.0 0.0 94.0 1 1 64.0]\n",
            " [1.0 0.0 0.0 81.0 1 1 75.0]\n",
            " [1.0 0.0 0.0 76.0 1 1 80.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEJCi9Fgmz-n"
      },
      "source": [
        "### Encoding dependent variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEYOn3J3Bcw4"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RT3rZDZhBumg",
        "outputId": "a7cece03-8dfc-416d-9166-125eae803e7b"
      },
      "source": [
        "print(y)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
            " 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.astype(np.float32)"
      ],
      "metadata": {
        "id": "WfLjcUAkNMjM"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yewVvsKENfU-",
        "outputId": "86201b21-6b97-4031-b252-48593b1df234"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.        0.        1.       10.        0.        0.       97.      ]\n",
            " [ 0.        0.        1.       12.        0.        0.       97.      ]\n",
            " [ 0.        0.        1.       15.        0.        0.       94.      ]\n",
            " [ 0.        0.        1.       10.        0.        0.       97.      ]\n",
            " [ 0.        1.        0.       13.        0.        0.       94.      ]\n",
            " [ 0.        1.        0.       12.        0.        0.       97.      ]\n",
            " [ 0.        1.        0.       13.        0.        0.       93.      ]\n",
            " [ 0.        1.        0.       15.        0.        0.       92.      ]\n",
            " [ 0.        1.        0.       18.        0.        0.       66.      ]\n",
            " [ 0.        0.        1.       19.        0.        0.       92.      ]\n",
            " [ 0.        0.        1.       20.        0.        0.       93.      ]\n",
            " [ 0.        0.        1.       17.        0.        0.       93.      ]\n",
            " [ 0.        0.        1.       16.        0.        0.       92.      ]\n",
            " [ 0.        0.        1.       18.        0.        0.       93.      ]\n",
            " [ 0.        0.        1.       20.        0.        0.       92.      ]\n",
            " [ 0.        1.        0.       25.        0.        0.       93.      ]\n",
            " [ 0.        1.        0.       24.        0.        0.       92.      ]\n",
            " [ 1.        0.        0.       26.        0.        0.       94.      ]\n",
            " [ 0.        0.        1.       28.        0.        0.       99.      ]\n",
            " [ 0.        0.        1.       29.        0.        0.       93.      ]\n",
            " [ 0.        1.        0.       30.        0.        0.       62.      ]\n",
            " [ 0.        0.        1.       19.        0.        0.       89.      ]\n",
            " [ 0.        0.        1.       25.        0.        1.       86.      ]\n",
            " [ 0.        0.        1.       26.        0.        0.       82.072464]\n",
            " [ 0.        0.        1.       28.        0.        0.       89.      ]\n",
            " [ 0.        1.        0.       30.        1.        0.       86.      ]\n",
            " [ 0.        1.        0.       35.        0.        0.       89.      ]\n",
            " [ 0.        1.        0.       32.        0.        1.       84.      ]\n",
            " [ 0.        1.        0.       45.130436  1.        0.       90.      ]\n",
            " [ 0.        1.        0.       32.        0.        0.       89.      ]\n",
            " [ 0.        1.        0.       35.        0.        1.       92.      ]\n",
            " [ 1.        0.        0.       38.        0.        0.       75.      ]\n",
            " [ 0.        1.        0.       40.        0.        1.       90.      ]\n",
            " [ 1.        0.        0.       46.        1.        0.       91.      ]\n",
            " [ 0.        1.        0.       48.        0.        1.       93.      ]\n",
            " [ 1.        0.        0.       42.        0.        0.       92.      ]\n",
            " [ 1.        0.        0.       40.        0.        0.       92.      ]\n",
            " [ 0.        1.        0.       49.        0.        0.       80.      ]\n",
            " [ 1.        0.        0.       50.        1.        1.       77.      ]\n",
            " [ 1.        0.        0.       36.        1.        0.       90.      ]\n",
            " [ 1.        0.        0.       52.        1.        1.       80.      ]\n",
            " [ 1.        0.        0.       56.        1.        1.       77.      ]\n",
            " [ 1.        0.        0.       58.        0.        0.       70.      ]\n",
            " [ 1.        0.        0.       59.        0.        1.       69.      ]\n",
            " [ 1.        0.        0.       60.        1.        1.       68.      ]\n",
            " [ 1.        0.        0.       53.        1.        0.       55.      ]\n",
            " [ 1.        0.        0.       54.        1.        1.       70.      ]\n",
            " [ 1.        0.        0.       62.        1.        1.       68.      ]\n",
            " [ 1.        0.        0.       63.        1.        1.       66.      ]\n",
            " [ 1.        0.        0.       68.        1.        0.       67.      ]\n",
            " [ 1.        0.        0.       69.        0.        1.       53.      ]\n",
            " [ 1.        0.        0.       64.        1.        1.       73.      ]\n",
            " [ 1.        0.        0.       61.        1.        1.       76.      ]\n",
            " [ 0.        0.        1.       70.        0.        1.       88.      ]\n",
            " [ 1.        0.        0.       59.        1.        0.       68.      ]\n",
            " [ 1.        0.        0.       62.        1.        1.       69.      ]\n",
            " [ 1.        0.        0.       78.        1.        1.       71.      ]\n",
            " [ 1.        0.        0.       74.        1.        1.       75.      ]\n",
            " [ 1.        0.        0.       75.        0.        1.       72.      ]\n",
            " [ 1.        0.        0.       56.        1.        0.       76.      ]\n",
            " [ 1.        0.        0.       80.        0.        1.       92.      ]\n",
            " [ 1.        0.        0.       82.        1.        1.       73.      ]\n",
            " [ 1.        0.        0.       86.        1.        1.       71.      ]\n",
            " [ 1.        0.        0.       90.        1.        1.       67.      ]\n",
            " [ 1.        0.        0.       84.        1.        1.       75.      ]\n",
            " [ 1.        0.        0.       86.        0.        1.       76.      ]\n",
            " [ 0.        1.        0.       61.        0.        1.       90.      ]\n",
            " [ 1.        0.        0.       94.        1.        1.       64.      ]\n",
            " [ 1.        0.        0.       81.        1.        1.       75.      ]\n",
            " [ 1.        0.        0.       76.        1.        1.       80.      ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bfz9vcDsm7r6"
      },
      "source": [
        "## Splitting data into Test set & Training Set\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ld4vnJbBC3sh"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rP7cBvClDnHk",
        "outputId": "46fd3580-acfe-41fd-a1e7-a17545e181fe"
      },
      "source": [
        "print(X_train)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.        0.        0.       59.        0.        1.       69.      ]\n",
            " [ 1.        0.        0.       74.        1.        1.       75.      ]\n",
            " [ 1.        0.        0.       86.        1.        1.       71.      ]\n",
            " [ 1.        0.        0.       61.        1.        1.       76.      ]\n",
            " [ 1.        0.        0.       62.        1.        1.       69.      ]\n",
            " [ 1.        0.        0.       62.        1.        1.       68.      ]\n",
            " [ 1.        0.        0.       64.        1.        1.       73.      ]\n",
            " [ 0.        1.        0.       48.        0.        1.       93.      ]\n",
            " [ 0.        0.        1.       19.        0.        0.       89.      ]\n",
            " [ 1.        0.        0.       56.        1.        0.       76.      ]\n",
            " [ 0.        0.        1.       10.        0.        0.       97.      ]\n",
            " [ 1.        0.        0.       50.        1.        1.       77.      ]\n",
            " [ 1.        0.        0.       46.        1.        0.       91.      ]\n",
            " [ 1.        0.        0.       75.        0.        1.       72.      ]\n",
            " [ 0.        0.        1.       20.        0.        0.       93.      ]\n",
            " [ 0.        1.        0.       25.        0.        0.       93.      ]\n",
            " [ 0.        0.        1.       29.        0.        0.       93.      ]\n",
            " [ 1.        0.        0.       52.        1.        1.       80.      ]\n",
            " [ 0.        0.        1.       28.        0.        0.       89.      ]\n",
            " [ 0.        1.        0.       18.        0.        0.       66.      ]\n",
            " [ 1.        0.        0.       26.        0.        0.       94.      ]\n",
            " [ 0.        0.        1.       10.        0.        0.       97.      ]\n",
            " [ 1.        0.        0.       90.        1.        1.       67.      ]\n",
            " [ 1.        0.        0.       60.        1.        1.       68.      ]\n",
            " [ 1.        0.        0.       82.        1.        1.       73.      ]\n",
            " [ 1.        0.        0.       94.        1.        1.       64.      ]\n",
            " [ 0.        0.        1.       18.        0.        0.       93.      ]\n",
            " [ 0.        0.        1.       25.        0.        1.       86.      ]\n",
            " [ 0.        1.        0.       40.        0.        1.       90.      ]\n",
            " [ 0.        1.        0.       35.        0.        1.       92.      ]\n",
            " [ 1.        0.        0.       56.        1.        1.       77.      ]\n",
            " [ 1.        0.        0.       54.        1.        1.       70.      ]\n",
            " [ 0.        0.        1.       26.        0.        0.       82.072464]\n",
            " [ 0.        1.        0.       13.        0.        0.       94.      ]\n",
            " [ 0.        0.        1.       20.        0.        0.       92.      ]\n",
            " [ 0.        1.        0.       32.        0.        0.       89.      ]\n",
            " [ 0.        1.        0.       45.130436  1.        0.       90.      ]\n",
            " [ 1.        0.        0.       58.        0.        0.       70.      ]\n",
            " [ 0.        0.        1.       17.        0.        0.       93.      ]\n",
            " [ 1.        0.        0.       78.        1.        1.       71.      ]\n",
            " [ 0.        0.        1.       28.        0.        0.       99.      ]\n",
            " [ 1.        0.        0.       76.        1.        1.       80.      ]\n",
            " [ 0.        1.        0.       30.        0.        0.       62.      ]\n",
            " [ 1.        0.        0.       69.        0.        1.       53.      ]\n",
            " [ 0.        1.        0.       30.        1.        0.       86.      ]\n",
            " [ 0.        1.        0.       13.        0.        0.       93.      ]\n",
            " [ 1.        0.        0.       53.        1.        0.       55.      ]\n",
            " [ 0.        1.        0.       15.        0.        0.       92.      ]\n",
            " [ 1.        0.        0.       81.        1.        1.       75.      ]\n",
            " [ 0.        0.        1.       12.        0.        0.       97.      ]\n",
            " [ 0.        1.        0.       24.        0.        0.       92.      ]\n",
            " [ 1.        0.        0.       84.        1.        1.       75.      ]\n",
            " [ 0.        1.        0.       12.        0.        0.       97.      ]\n",
            " [ 0.        0.        1.       19.        0.        0.       92.      ]\n",
            " [ 0.        0.        1.       16.        0.        0.       92.      ]\n",
            " [ 0.        1.        0.       49.        0.        0.       80.      ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vf-1vDU2DqgW",
        "outputId": "8568e368-7219-4919-ee4d-25947a2f23ad"
      },
      "source": [
        "print(X_test)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.  0.  0. 86.  0.  1. 76.]\n",
            " [ 0.  1.  0. 35.  0.  0. 89.]\n",
            " [ 0.  1.  0. 61.  0.  1. 90.]\n",
            " [ 1.  0.  0. 59.  1.  0. 68.]\n",
            " [ 0.  1.  0. 32.  0.  1. 84.]\n",
            " [ 1.  0.  0. 80.  0.  1. 92.]\n",
            " [ 1.  0.  0. 68.  1.  0. 67.]\n",
            " [ 1.  0.  0. 40.  0.  0. 92.]\n",
            " [ 1.  0.  0. 63.  1.  1. 66.]\n",
            " [ 1.  0.  0. 38.  0.  0. 75.]\n",
            " [ 0.  0.  1. 15.  0.  0. 94.]\n",
            " [ 1.  0.  0. 36.  1.  0. 90.]\n",
            " [ 0.  0.  1. 70.  0.  1. 88.]\n",
            " [ 1.  0.  0. 42.  0.  0. 92.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fykcMDsNDtJA",
        "outputId": "0982c5db-dcee-4a2a-9928-5441ad8321c2"
      },
      "source": [
        "print(y_train)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 1 1 1 1 0 0 1 0 1 0 1 0 0 0 1 0 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 0 0 0\n",
            " 1 0 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPLdwNWdD13h",
        "outputId": "3482016a-e165-4c92-ab34-ee9bac32444a"
      },
      "source": [
        "print(y_test)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 0 1 0 0 1 0 1 1 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5uoHf8MsQG0"
      },
      "source": [
        "## Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pE6_puPBEXjk"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train[:, 6:] = sc.fit_transform(X_train[:, 6:])\n",
        "X_test[:, 6:] = sc.fit_transform(X_test[:, 6:])"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GL__8qhIGYxI",
        "outputId": "ee04c9ee-341f-423f-af1a-831561127521"
      },
      "source": [
        "print(X_train)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.0000000e+00  0.0000000e+00  0.0000000e+00  5.9000000e+01\n",
            "   0.0000000e+00  1.0000000e+00 -1.0803987e+00]\n",
            " [ 1.0000000e+00  0.0000000e+00  0.0000000e+00  7.4000000e+01\n",
            "   1.0000000e+00  1.0000000e+00 -5.7485926e-01]\n",
            " [ 1.0000000e+00  0.0000000e+00  0.0000000e+00  8.6000000e+01\n",
            "   1.0000000e+00  1.0000000e+00 -9.1188556e-01]\n",
            " [ 1.0000000e+00  0.0000000e+00  0.0000000e+00  6.1000000e+01\n",
            "   1.0000000e+00  1.0000000e+00 -4.9060267e-01]\n",
            " [ 1.0000000e+00  0.0000000e+00  0.0000000e+00  6.2000000e+01\n",
            "   1.0000000e+00  1.0000000e+00 -1.0803987e+00]\n",
            " [ 1.0000000e+00  0.0000000e+00  0.0000000e+00  6.2000000e+01\n",
            "   1.0000000e+00  1.0000000e+00 -1.1646553e+00]\n",
            " [ 1.0000000e+00  0.0000000e+00  0.0000000e+00  6.4000000e+01\n",
            "   1.0000000e+00  1.0000000e+00 -7.4337238e-01]\n",
            " [ 0.0000000e+00  1.0000000e+00  0.0000000e+00  4.8000000e+01\n",
            "   0.0000000e+00  1.0000000e+00  9.4175917e-01]\n",
            " [ 0.0000000e+00  0.0000000e+00  1.0000000e+00  1.9000000e+01\n",
            "   0.0000000e+00  0.0000000e+00  6.0473281e-01]\n",
            " [ 1.0000000e+00  0.0000000e+00  0.0000000e+00  5.6000000e+01\n",
            "   1.0000000e+00  0.0000000e+00 -4.9060267e-01]\n",
            " [ 0.0000000e+00  0.0000000e+00  1.0000000e+00  1.0000000e+01\n",
            "   0.0000000e+00  0.0000000e+00  1.2787855e+00]\n",
            " [ 1.0000000e+00  0.0000000e+00  0.0000000e+00  5.0000000e+01\n",
            "   1.0000000e+00  1.0000000e+00 -4.0634608e-01]\n",
            " [ 1.0000000e+00  0.0000000e+00  0.0000000e+00  4.6000000e+01\n",
            "   1.0000000e+00  0.0000000e+00  7.7324599e-01]\n",
            " [ 1.0000000e+00  0.0000000e+00  0.0000000e+00  7.5000000e+01\n",
            "   0.0000000e+00  1.0000000e+00 -8.2762897e-01]\n",
            " [ 0.0000000e+00  0.0000000e+00  1.0000000e+00  2.0000000e+01\n",
            "   0.0000000e+00  0.0000000e+00  9.4175917e-01]\n",
            " [ 0.0000000e+00  1.0000000e+00  0.0000000e+00  2.5000000e+01\n",
            "   0.0000000e+00  0.0000000e+00  9.4175917e-01]\n",
            " [ 0.0000000e+00  0.0000000e+00  1.0000000e+00  2.9000000e+01\n",
            "   0.0000000e+00  0.0000000e+00  9.4175917e-01]\n",
            " [ 1.0000000e+00  0.0000000e+00  0.0000000e+00  5.2000000e+01\n",
            "   1.0000000e+00  1.0000000e+00 -1.5357636e-01]\n",
            " [ 0.0000000e+00  0.0000000e+00  1.0000000e+00  2.8000000e+01\n",
            "   0.0000000e+00  0.0000000e+00  6.0473281e-01]\n",
            " [ 0.0000000e+00  1.0000000e+00  0.0000000e+00  1.8000000e+01\n",
            "   0.0000000e+00  0.0000000e+00 -1.3331684e+00]\n",
            " [ 1.0000000e+00  0.0000000e+00  0.0000000e+00  2.6000000e+01\n",
            "   0.0000000e+00  0.0000000e+00  1.0260158e+00]\n",
            " [ 0.0000000e+00  0.0000000e+00  1.0000000e+00  1.0000000e+01\n",
            "   0.0000000e+00  0.0000000e+00  1.2787855e+00]\n",
            " [ 1.0000000e+00  0.0000000e+00  0.0000000e+00  9.0000000e+01\n",
            "   1.0000000e+00  1.0000000e+00 -1.2489119e+00]\n",
            " [ 1.0000000e+00  0.0000000e+00  0.0000000e+00  6.0000000e+01\n",
            "   1.0000000e+00  1.0000000e+00 -1.1646553e+00]\n",
            " [ 1.0000000e+00  0.0000000e+00  0.0000000e+00  8.2000000e+01\n",
            "   1.0000000e+00  1.0000000e+00 -7.4337238e-01]\n",
            " [ 1.0000000e+00  0.0000000e+00  0.0000000e+00  9.4000000e+01\n",
            "   1.0000000e+00  1.0000000e+00 -1.5016817e+00]\n",
            " [ 0.0000000e+00  0.0000000e+00  1.0000000e+00  1.8000000e+01\n",
            "   0.0000000e+00  0.0000000e+00  9.4175917e-01]\n",
            " [ 0.0000000e+00  0.0000000e+00  1.0000000e+00  2.5000000e+01\n",
            "   0.0000000e+00  1.0000000e+00  3.5196310e-01]\n",
            " [ 0.0000000e+00  1.0000000e+00  0.0000000e+00  4.0000000e+01\n",
            "   0.0000000e+00  1.0000000e+00  6.8898940e-01]\n",
            " [ 0.0000000e+00  1.0000000e+00  0.0000000e+00  3.5000000e+01\n",
            "   0.0000000e+00  1.0000000e+00  8.5750258e-01]\n",
            " [ 1.0000000e+00  0.0000000e+00  0.0000000e+00  5.6000000e+01\n",
            "   1.0000000e+00  1.0000000e+00 -4.0634608e-01]\n",
            " [ 1.0000000e+00  0.0000000e+00  0.0000000e+00  5.4000000e+01\n",
            "   1.0000000e+00  1.0000000e+00 -9.9614209e-01]\n",
            " [ 0.0000000e+00  0.0000000e+00  1.0000000e+00  2.6000000e+01\n",
            "   0.0000000e+00  0.0000000e+00  2.1042356e-02]\n",
            " [ 0.0000000e+00  1.0000000e+00  0.0000000e+00  1.3000000e+01\n",
            "   0.0000000e+00  0.0000000e+00  1.0260158e+00]\n",
            " [ 0.0000000e+00  0.0000000e+00  1.0000000e+00  2.0000000e+01\n",
            "   0.0000000e+00  0.0000000e+00  8.5750258e-01]\n",
            " [ 0.0000000e+00  1.0000000e+00  0.0000000e+00  3.2000000e+01\n",
            "   0.0000000e+00  0.0000000e+00  6.0473281e-01]\n",
            " [ 0.0000000e+00  1.0000000e+00  0.0000000e+00  4.5130436e+01\n",
            "   1.0000000e+00  0.0000000e+00  6.8898940e-01]\n",
            " [ 1.0000000e+00  0.0000000e+00  0.0000000e+00  5.8000000e+01\n",
            "   0.0000000e+00  0.0000000e+00 -9.9614209e-01]\n",
            " [ 0.0000000e+00  0.0000000e+00  1.0000000e+00  1.7000000e+01\n",
            "   0.0000000e+00  0.0000000e+00  9.4175917e-01]\n",
            " [ 1.0000000e+00  0.0000000e+00  0.0000000e+00  7.8000000e+01\n",
            "   1.0000000e+00  1.0000000e+00 -9.1188556e-01]\n",
            " [ 0.0000000e+00  0.0000000e+00  1.0000000e+00  2.8000000e+01\n",
            "   0.0000000e+00  0.0000000e+00  1.4472985e+00]\n",
            " [ 1.0000000e+00  0.0000000e+00  0.0000000e+00  7.6000000e+01\n",
            "   1.0000000e+00  1.0000000e+00 -1.5357636e-01]\n",
            " [ 0.0000000e+00  1.0000000e+00  0.0000000e+00  3.0000000e+01\n",
            "   0.0000000e+00  0.0000000e+00 -1.6701949e+00]\n",
            " [ 1.0000000e+00  0.0000000e+00  0.0000000e+00  6.9000000e+01\n",
            "   0.0000000e+00  1.0000000e+00 -2.4285040e+00]\n",
            " [ 0.0000000e+00  1.0000000e+00  0.0000000e+00  3.0000000e+01\n",
            "   1.0000000e+00  0.0000000e+00  3.5196310e-01]\n",
            " [ 0.0000000e+00  1.0000000e+00  0.0000000e+00  1.3000000e+01\n",
            "   0.0000000e+00  0.0000000e+00  9.4175917e-01]\n",
            " [ 1.0000000e+00  0.0000000e+00  0.0000000e+00  5.3000000e+01\n",
            "   1.0000000e+00  0.0000000e+00 -2.2599909e+00]\n",
            " [ 0.0000000e+00  1.0000000e+00  0.0000000e+00  1.5000000e+01\n",
            "   0.0000000e+00  0.0000000e+00  8.5750258e-01]\n",
            " [ 1.0000000e+00  0.0000000e+00  0.0000000e+00  8.1000000e+01\n",
            "   1.0000000e+00  1.0000000e+00 -5.7485926e-01]\n",
            " [ 0.0000000e+00  0.0000000e+00  1.0000000e+00  1.2000000e+01\n",
            "   0.0000000e+00  0.0000000e+00  1.2787855e+00]\n",
            " [ 0.0000000e+00  1.0000000e+00  0.0000000e+00  2.4000000e+01\n",
            "   0.0000000e+00  0.0000000e+00  8.5750258e-01]\n",
            " [ 1.0000000e+00  0.0000000e+00  0.0000000e+00  8.4000000e+01\n",
            "   1.0000000e+00  1.0000000e+00 -5.7485926e-01]\n",
            " [ 0.0000000e+00  1.0000000e+00  0.0000000e+00  1.2000000e+01\n",
            "   0.0000000e+00  0.0000000e+00  1.2787855e+00]\n",
            " [ 0.0000000e+00  0.0000000e+00  1.0000000e+00  1.9000000e+01\n",
            "   0.0000000e+00  0.0000000e+00  8.5750258e-01]\n",
            " [ 0.0000000e+00  0.0000000e+00  1.0000000e+00  1.6000000e+01\n",
            "   0.0000000e+00  0.0000000e+00  8.5750258e-01]\n",
            " [ 0.0000000e+00  1.0000000e+00  0.0000000e+00  4.9000000e+01\n",
            "   0.0000000e+00  0.0000000e+00 -1.5357636e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Analysis using ANN**"
      ],
      "metadata": {
        "id": "h6J0NiQPHqRB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining Model"
      ],
      "metadata": {
        "id": "UNYgOnvhHzfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "input_dim=X_train.shape[1]\n",
        "\n",
        "model=Sequential([Dense(64,activation='relu',input_shape=(input_dim,)),\n",
        "                  Dense(32,activation='relu'),\n",
        "                  Dense(1,activation='sigmoid')])\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "8UVYbZv9H2sP",
        "outputId": "38c17ffc-00e3-418e-db54-cb5a1fd053ba"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,625\u001b[0m (10.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,625</span> (10.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,625\u001b[0m (10.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,625</span> (10.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the model"
      ],
      "metadata": {
        "id": "NKsl3H7YJpS8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(X_train,y_train,batch_size=32,epochs=101,validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3ernEwDJru7",
        "outputId": "23353784-82c6-44e5-e942-978f72e53c25"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 337ms/step - accuracy: 0.5152 - loss: 0.7512 - val_accuracy: 0.3333 - val_loss: 0.6388\n",
            "Epoch 2/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.5152 - loss: 0.5949 - val_accuracy: 0.3333 - val_loss: 0.6939\n",
            "Epoch 3/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.5256 - loss: 0.6632 - val_accuracy: 0.3333 - val_loss: 0.6851\n",
            "Epoch 4/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.5047 - loss: 0.6600 - val_accuracy: 0.3333 - val_loss: 0.6365\n",
            "Epoch 5/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5047 - loss: 0.6144 - val_accuracy: 0.4167 - val_loss: 0.5950\n",
            "Epoch 6/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.4943 - loss: 0.5763 - val_accuracy: 0.6667 - val_loss: 0.5788\n",
            "Epoch 7/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.5814 - loss: 0.5644 - val_accuracy: 0.8333 - val_loss: 0.5701\n",
            "Epoch 8/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.6638 - loss: 0.5461 - val_accuracy: 0.6667 - val_loss: 0.5610\n",
            "Epoch 9/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.6127 - loss: 0.5312 - val_accuracy: 0.6667 - val_loss: 0.5538\n",
            "Epoch 10/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.6023 - loss: 0.5210 - val_accuracy: 0.6667 - val_loss: 0.5453\n",
            "Epoch 11/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.5710 - loss: 0.5401 - val_accuracy: 0.7500 - val_loss: 0.5362\n",
            "Epoch 12/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.5966 - loss: 0.5247 - val_accuracy: 0.7500 - val_loss: 0.5305\n",
            "Epoch 13/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6174 - loss: 0.5070 - val_accuracy: 0.7500 - val_loss: 0.5251\n",
            "Epoch 14/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.6070 - loss: 0.4989 - val_accuracy: 0.7500 - val_loss: 0.5159\n",
            "Epoch 15/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.6430 - loss: 0.4812 - val_accuracy: 0.9167 - val_loss: 0.5033\n",
            "Epoch 16/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.7500 - loss: 0.4818 - val_accuracy: 0.9167 - val_loss: 0.4918\n",
            "Epoch 17/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.8419 - loss: 0.4721 - val_accuracy: 0.9167 - val_loss: 0.4839\n",
            "Epoch 18/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.9186 - loss: 0.4613 - val_accuracy: 0.9167 - val_loss: 0.4762\n",
            "Epoch 19/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.9233 - loss: 0.4745 - val_accuracy: 0.9167 - val_loss: 0.4680\n",
            "Epoch 20/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.8977 - loss: 0.4684 - val_accuracy: 0.9167 - val_loss: 0.4624\n",
            "Epoch 21/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7547 - loss: 0.4622 - val_accuracy: 0.9167 - val_loss: 0.4664\n",
            "Epoch 22/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7453 - loss: 0.4512 - val_accuracy: 0.8333 - val_loss: 0.4701\n",
            "Epoch 23/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.6884 - loss: 0.4724 - val_accuracy: 0.9167 - val_loss: 0.4554\n",
            "Epoch 24/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.7292 - loss: 0.4561 - val_accuracy: 0.9167 - val_loss: 0.4374\n",
            "Epoch 25/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.8011 - loss: 0.4307 - val_accuracy: 0.9167 - val_loss: 0.4249\n",
            "Epoch 26/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.8722 - loss: 0.4233 - val_accuracy: 1.0000 - val_loss: 0.4178\n",
            "Epoch 27/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.9233 - loss: 0.4145 - val_accuracy: 0.9167 - val_loss: 0.4107\n",
            "Epoch 28/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.9441 - loss: 0.4011 - val_accuracy: 0.9167 - val_loss: 0.4048\n",
            "Epoch 29/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.9290 - loss: 0.3988 - val_accuracy: 0.9167 - val_loss: 0.3996\n",
            "Epoch 30/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.8930 - loss: 0.3886 - val_accuracy: 0.9167 - val_loss: 0.3924\n",
            "Epoch 31/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.8977 - loss: 0.3771 - val_accuracy: 0.9167 - val_loss: 0.3840\n",
            "Epoch 32/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.9233 - loss: 0.3816 - val_accuracy: 1.0000 - val_loss: 0.3772\n",
            "Epoch 33/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.9489 - loss: 0.3675 - val_accuracy: 1.0000 - val_loss: 0.3712\n",
            "Epoch 34/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.9744 - loss: 0.3647 - val_accuracy: 1.0000 - val_loss: 0.3642\n",
            "Epoch 35/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.9744 - loss: 0.3584 - val_accuracy: 1.0000 - val_loss: 0.3570\n",
            "Epoch 36/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.9489 - loss: 0.3538 - val_accuracy: 1.0000 - val_loss: 0.3501\n",
            "Epoch 37/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.9489 - loss: 0.3489 - val_accuracy: 0.9167 - val_loss: 0.3444\n",
            "Epoch 38/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.9337 - loss: 0.3381 - val_accuracy: 1.0000 - val_loss: 0.3381\n",
            "Epoch 39/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.9337 - loss: 0.3354 - val_accuracy: 1.0000 - val_loss: 0.3306\n",
            "Epoch 40/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.9593 - loss: 0.3311 - val_accuracy: 1.0000 - val_loss: 0.3248\n",
            "Epoch 41/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.9744 - loss: 0.3275 - val_accuracy: 1.0000 - val_loss: 0.3193\n",
            "Epoch 42/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.9744 - loss: 0.3149 - val_accuracy: 1.0000 - val_loss: 0.3127\n",
            "Epoch 43/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.9744 - loss: 0.3155 - val_accuracy: 0.9167 - val_loss: 0.3068\n",
            "Epoch 44/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.9848 - loss: 0.3012 - val_accuracy: 1.0000 - val_loss: 0.3000\n",
            "Epoch 45/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.9744 - loss: 0.2966 - val_accuracy: 1.0000 - val_loss: 0.2938\n",
            "Epoch 46/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.9489 - loss: 0.2962 - val_accuracy: 1.0000 - val_loss: 0.2885\n",
            "Epoch 47/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.9489 - loss: 0.2906 - val_accuracy: 1.0000 - val_loss: 0.2825\n",
            "Epoch 48/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.9744 - loss: 0.2814 - val_accuracy: 0.9167 - val_loss: 0.2782\n",
            "Epoch 49/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.9848 - loss: 0.2725 - val_accuracy: 0.9167 - val_loss: 0.2765\n",
            "Epoch 50/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.9489 - loss: 0.2831 - val_accuracy: 0.9167 - val_loss: 0.2719\n",
            "Epoch 51/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9593 - loss: 0.2658 - val_accuracy: 0.9167 - val_loss: 0.2626\n",
            "Epoch 52/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.9848 - loss: 0.2532 - val_accuracy: 1.0000 - val_loss: 0.2563\n",
            "Epoch 53/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.9744 - loss: 0.2502 - val_accuracy: 0.9167 - val_loss: 0.2539\n",
            "Epoch 54/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9489 - loss: 0.2567 - val_accuracy: 0.9167 - val_loss: 0.2524\n",
            "Epoch 55/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.9593 - loss: 0.2403 - val_accuracy: 0.9167 - val_loss: 0.2464\n",
            "Epoch 56/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.9489 - loss: 0.2476 - val_accuracy: 0.9167 - val_loss: 0.2395\n",
            "Epoch 57/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.9848 - loss: 0.2283 - val_accuracy: 0.9167 - val_loss: 0.2334\n",
            "Epoch 58/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.9744 - loss: 0.2329 - val_accuracy: 0.9167 - val_loss: 0.2294\n",
            "Epoch 59/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.9848 - loss: 0.2176 - val_accuracy: 0.9167 - val_loss: 0.2275\n",
            "Epoch 60/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.9848 - loss: 0.2159 - val_accuracy: 0.9167 - val_loss: 0.2277\n",
            "Epoch 61/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.9697 - loss: 0.2072 - val_accuracy: 0.9167 - val_loss: 0.2264\n",
            "Epoch 62/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.9593 - loss: 0.2081 - val_accuracy: 0.9167 - val_loss: 0.2220\n",
            "Epoch 63/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.9489 - loss: 0.2143 - val_accuracy: 0.9167 - val_loss: 0.2131\n",
            "Epoch 64/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.9848 - loss: 0.1989 - val_accuracy: 0.9167 - val_loss: 0.2063\n",
            "Epoch 65/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.9848 - loss: 0.1952 - val_accuracy: 0.9167 - val_loss: 0.2032\n",
            "Epoch 66/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.9744 - loss: 0.1996 - val_accuracy: 0.9167 - val_loss: 0.2030\n",
            "Epoch 67/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.9744 - loss: 0.2003 - val_accuracy: 0.9167 - val_loss: 0.2016\n",
            "Epoch 68/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.9848 - loss: 0.1822 - val_accuracy: 0.9167 - val_loss: 0.1997\n",
            "Epoch 69/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.9593 - loss: 0.1796 - val_accuracy: 0.9167 - val_loss: 0.2017\n",
            "Epoch 70/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.9593 - loss: 0.1767 - val_accuracy: 0.9167 - val_loss: 0.2044\n",
            "Epoch 71/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.9489 - loss: 0.1905 - val_accuracy: 0.9167 - val_loss: 0.1993\n",
            "Epoch 72/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.9593 - loss: 0.1711 - val_accuracy: 0.9167 - val_loss: 0.1881\n",
            "Epoch 73/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.9848 - loss: 0.1692 - val_accuracy: 0.9167 - val_loss: 0.1786\n",
            "Epoch 74/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.9744 - loss: 0.1755 - val_accuracy: 0.9167 - val_loss: 0.1750\n",
            "Epoch 75/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.9744 - loss: 0.1730 - val_accuracy: 0.9167 - val_loss: 0.1736\n",
            "Epoch 76/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9848 - loss: 0.1477 - val_accuracy: 0.9167 - val_loss: 0.1790\n",
            "Epoch 77/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.9744 - loss: 0.1560 - val_accuracy: 0.9167 - val_loss: 0.1907\n",
            "Epoch 78/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9593 - loss: 0.1457 - val_accuracy: 0.9167 - val_loss: 0.1876\n",
            "Epoch 79/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.9489 - loss: 0.1482 - val_accuracy: 0.9167 - val_loss: 0.1733\n",
            "Epoch 80/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.9744 - loss: 0.1421 - val_accuracy: 0.9167 - val_loss: 0.1602\n",
            "Epoch 81/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.9744 - loss: 0.1391 - val_accuracy: 0.9167 - val_loss: 0.1532\n",
            "Epoch 82/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.9848 - loss: 0.1361 - val_accuracy: 0.9167 - val_loss: 0.1508\n",
            "Epoch 83/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.9744 - loss: 0.1433 - val_accuracy: 0.9167 - val_loss: 0.1552\n",
            "Epoch 84/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.9744 - loss: 0.1295 - val_accuracy: 0.9167 - val_loss: 0.1654\n",
            "Epoch 85/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.9744 - loss: 0.1272 - val_accuracy: 0.9167 - val_loss: 0.1716\n",
            "Epoch 86/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.9744 - loss: 0.1281 - val_accuracy: 0.9167 - val_loss: 0.1648\n",
            "Epoch 87/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.9848 - loss: 0.1117 - val_accuracy: 0.9167 - val_loss: 0.1554\n",
            "Epoch 88/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.9848 - loss: 0.1122 - val_accuracy: 0.9167 - val_loss: 0.1533\n",
            "Epoch 89/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.9744 - loss: 0.1104 - val_accuracy: 0.9167 - val_loss: 0.1565\n",
            "Epoch 90/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.9848 - loss: 0.1116 - val_accuracy: 0.9167 - val_loss: 0.1617\n",
            "Epoch 91/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.9744 - loss: 0.1158 - val_accuracy: 0.9167 - val_loss: 0.1645\n",
            "Epoch 92/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.9848 - loss: 0.1004 - val_accuracy: 0.9167 - val_loss: 0.1641\n",
            "Epoch 93/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.9744 - loss: 0.1076 - val_accuracy: 0.9167 - val_loss: 0.1589\n",
            "Epoch 94/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.9744 - loss: 0.1041 - val_accuracy: 0.9167 - val_loss: 0.1522\n",
            "Epoch 95/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.9744 - loss: 0.1071 - val_accuracy: 0.9167 - val_loss: 0.1495\n",
            "Epoch 96/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9744 - loss: 0.0996 - val_accuracy: 0.9167 - val_loss: 0.1492\n",
            "Epoch 97/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.9744 - loss: 0.0982 - val_accuracy: 0.9167 - val_loss: 0.1472\n",
            "Epoch 98/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.9744 - loss: 0.0966 - val_accuracy: 0.9167 - val_loss: 0.1446\n",
            "Epoch 99/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.9848 - loss: 0.0886 - val_accuracy: 0.9167 - val_loss: 0.1456\n",
            "Epoch 100/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.9744 - loss: 0.0898 - val_accuracy: 0.9167 - val_loss: 0.1557\n",
            "Epoch 101/101\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.9744 - loss: 0.0944 - val_accuracy: 0.9167 - val_loss: 0.1625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating on Test Set"
      ],
      "metadata": {
        "id": "7kc55f5jOZ6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss,accuracy=model.evaluate(X_test,y_test)\n",
        "print(f\"Loss: {loss:.4f}\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ck54nrdQN4EF",
        "outputId": "fa40a4b6-963e-4613-edfd-ae86115256bf"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 1.0000 - loss: 0.2008\n",
            "Loss: 0.2008\n",
            "Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction"
      ],
      "metadata": {
        "id": "VA0PGajHOf0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred=model.predict(X_test)\n",
        "Y_pred=(Y_pred>0.5)\n",
        "print(np.concatenate((Y_pred.reshape(len(Y_pred),1), y_test.reshape(len(y_test),1)),axis=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IYTbwmMOYai",
        "outputId": "8eb42dce-9bb2-4f2d-a397-5b0872770ad0"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "[[1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion Matrix"
      ],
      "metadata": {
        "id": "f0KP92hzQSx0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm=confusion_matrix(y_test,Y_pred)\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcJVF1H9QaEZ",
        "outputId": "b97d5c69-cbb6-4271-a5a3-1b87fafea368"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[9 0]\n",
            " [0 5]]\n"
          ]
        }
      ]
    }
  ]
}